{
  "Mistral AI": "Mistral AI",
  "Mistral AI provides state-of-the-art open-weight and hosted language models for text generation, embeddings, and reasoning tasks.": "Mistral AI provides state-of-the-art open-weight and hosted language models for text generation, embeddings, and reasoning tasks.",
  "You can obtain your API key from the Mistral AI dashboard. Go to https://console.mistral.ai, generate an API key, and paste it here.": "You can obtain your API key from the Mistral AI dashboard. Go to https://console.mistral.ai, generate an API key, and paste it here.",
  "Ask Mistral": "Ask Mistral",
  "Create Embeddings": "Create Embeddings",
  "Upload File": "Upload File",
  "List Models": "List Models",
  "Custom API Call": "Custom API Call",
  "Ask Mistral anything you want!": "Ask Mistral anything you want!",
  "Creates new embedding in Mistral AI.": "Creates new embedding in Mistral AI.",
  "Upload a file to Mistral AI (e.g., for fine-tuning or context storage).": "Upload a file to Mistral AI (e.g., for fine-tuning or context storage).",
  "Retrieves a list of available Mistral AI models.": "Retrieves a list of available Mistral AI models.",
  "Make a custom API call to a specific endpoint": "Make a custom API call to a specific endpoint",
  "Model": "Model",
  "Question": "Question",
  "Temperature": "Temperature",
  "Top P": "Top P",
  "Max Tokens": "Max Tokens",
  "Random Seed": "Random Seed",
  "Timeout (ms)": "Timeout (ms)",
  "Input": "Input",
  "File": "File",
  "Purpose": "Purpose",
  "Method": "Method",
  "Headers": "Headers",
  "Query Parameters": "Query Parameters",
  "Body": "Body",
  "No Error on Failure": "No Error on Failure",
  "Timeout (in seconds)": "Timeout (in seconds)",
  "Select a Mistral model. List is fetched live from your account.": "Select a Mistral model. List is fetched live from your account.",
  "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.": "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.",
  "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.",
  "The input text for which to create an embedding.": "The input text for which to create an embedding.",
  "The file to upload (max 512MB).For fine tuning purspose provide .jsonl file.": "The file to upload (max 512MB).For fine tuning purspose provide .jsonl file.",
  "Purpose of the file.": "Purpose of the file.",
  "Authorization headers are injected automatically from your connection.": "Authorization headers are injected automatically from your connection.",
  "fine-tune": "fine-tune",
  "batch": "batch",
  "ocr": "ocr",
  "GET": "GET",
  "POST": "POST",
  "PATCH": "PATCH",
  "PUT": "PUT",
  "DELETE": "DELETE",
  "HEAD": "HEAD"
}