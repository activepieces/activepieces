{
  "OpenRouter": "OpenRouter",
  "Use any AI model to generate code, text, or images via OpenRouter.ai.": "Verwenden Sie jedes KI-Modell um Code, Text oder Bilder über OpenRouter.ai zu generieren.",
  "\nFollow these instructions to get your OpenAI API Key:\n\n1. Visit the following website: https://openrouter.ai/keys.\n2. Once on the website, click on create a key.\n3. Once you have created a key, copy it and use it for the Api key field on the site.\n": "\nFolgen Sie diesen Anweisungen, um Ihren OpenAI-API-Schlüssel zu erhalten:\n\n1. Besuchen Sie die folgende Website: https://openrouter.ai/keys.\n2. Sobald Sie auf der Webseite sind, klicken Sie auf einen Schlüssel erstellen.\n3. Sobald Sie einen Schlüssel erstellt haben, kopieren Sie ihn und verwenden Sie ihn für das Api-Schlüsselfeld auf der Seite.\n",
  "Ask LLM": "LLM fragen",
  "Custom API Call": "Eigener API-Aufruf",
  "Ask any model supported by Open Router.": "Fragen Sie jedes Modell, das von Open Router unterstützt wird.",
  "Make a custom API call to a specific endpoint": "Einen benutzerdefinierten API-Aufruf an einen bestimmten Endpunkt machen",
  "Model": "Modell",
  "Prompt": "Prompt",
  "Temperature": "Temperatur",
  "Maximum Tokens": "Maximale Token",
  "Top P": "Oben P",
  "Method": "Methode",
  "Headers": "Kopfzeilen",
  "Query Parameters": "Abfrageparameter",
  "Body": "Körper",
  "No Error on Failure": "Kein Fehler bei Fehler",
  "Timeout (in seconds)": "Timeout (in Sekunden)",
  "The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code.": "Das Modell, das die Vervollständigung generiert. Einige Modelle eignen sich für Aufgaben der natürlichen Sprache, andere sind auf Code spezialisiert.",
  "The prompt to send to the model.": "Die Eingabeaufforderung, die an das Modell gesendet wird.",
  "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.": "Kontrolliert Zufallszufälligkeit: Die Verringerung führt zu weniger zufälligen Vervollständigungen. Je näher die Temperatur Null rückt, desto deterministischer und sich wiederholender wird.",
  "The maximum number of tokens to generate. Requests can use up to 2,048 or 4,096 tokens shared between prompt and completion, don't set the value to maximum and leave some tokens for the input. The exact limit varies by model. (One token is roughly 4 characters for normal English text)": "Die maximale Anzahl der zu generierenden Token. Anfragen können bis zu 2.048 oder 4.096 Token verwenden, die zwischen Prompt und Fertigstellung geteilt werden, setzen Sie den Wert nicht auf maximal und lassen Sie einige Token für die Eingabe. Das genaue Limit variiert je nach Modell. (Ein Token ist ungefähr 4 Zeichen für den normalen englischen Text)",
  "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.": "Eine Alternative zur Probenahme mit Temperatur, genannt Nucleus Probenahme, bei der das Modell die Ergebnisse der Tokens mit der Top_p Wahrscheinlichkeitsmasse berücksichtigt. 0,1 bedeutet also nur die Token, die die obersten 10% Wahrscheinlichkeitsmasse ausmachen.",
  "Authorization headers are injected automatically from your connection.": "Autorisierungs-Header werden automatisch von Ihrer Verbindung injiziert.",
  "GET": "ERHALTEN",
  "POST": "POST",
  "PATCH": "PATCH",
  "PUT": "PUT",
  "DELETE": "LÖSCHEN",
  "HEAD": "HEAD"
}