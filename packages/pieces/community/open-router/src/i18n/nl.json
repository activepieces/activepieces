{
  "OpenRouter": "OpenRouter",
  "Use any AI model to generate code, text, or images via OpenRouter.ai.": "Gebruik een AI-model om code, tekst of afbeeldingen te genereren via OpenRouter.ai.",
  "\nFollow these instructions to get your OpenAI API Key:\n\n1. Visit the following website: https://openrouter.ai/keys.\n2. Once on the website, click on create a key.\n3. Once you have created a key, copy it and use it for the Api key field on the site.\n": "\nVolg deze instructies om uw OpenAI API Key te verkrijgen:\n\n1. Bezoek de volgende website: https://openrouter.ai/keys.\n2. Eenmaal op de website, klik op een sleutel maken.\n3. Zodra u een sleutel heeft gemaakt, kopieer deze en gebruik deze voor het veld Api sleutel op de site.\n",
  "Ask LLM": "Vraag LLLM",
  "Custom API Call": "Custom API Call",
  "Ask any model supported by Open Router.": "Vraag elk model dat wordt ondersteund door Open Router.",
  "Make a custom API call to a specific endpoint": "Maak een aangepaste API call naar een specifiek eindpunt",
  "Model": "Model",
  "Prompt": "Prompt",
  "Temperature": "Temperatuur",
  "Maximum Tokens": "Maximaal aantal tokens",
  "Top P": "Boven P",
  "Method": "Methode",
  "Headers": "Kopteksten",
  "Query Parameters": "Query parameters",
  "Body": "Lichaam",
  "No Error on Failure": "Geen fout bij fout",
  "Timeout (in seconds)": "Time-out (in seconden)",
  "The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code.": "Het model dat de voltooiing zal genereren. Sommige modellen zijn geschikt voor natuurlijke taaltaken, andere zijn gespecialiseerd in code.",
  "The prompt to send to the model.": "De prompt om naar het model te sturen.",
  "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.": "Bestuurt willekeurigheid: Het verlagen van de temperatuur resulteert in minder willekeurige aanvullingen. Zodra de temperatuur nul nadert, zal het model deterministisch en herhalend worden.",
  "The maximum number of tokens to generate. Requests can use up to 2,048 or 4,096 tokens shared between prompt and completion, don't set the value to maximum and leave some tokens for the input. The exact limit varies by model. (One token is roughly 4 characters for normal English text)": "Het maximum aantal te genereren tokens Verzoeken kunnen maximaal 2.048 of 4.096 tokens gedeeld worden tussen prompt en voltooiing, stel de waarde niet in op maximum en laat sommige tokens voor de invoer. De exacte limiet varieert per model. (Eén token is grofweg 4 tekens voor normale Engelse tekst)",
  "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.": "Een alternatief voor bemonstering met de temperatuur, genaamd nucleus sampling, waarbij het model de resultaten van de tokens met top_p waarschijnlijkheid ziet. 0.1 betekent dus dat alleen de tokens die de grootste massa van 10 procent vormen, worden overwogen.",
  "Authorization headers are injected automatically from your connection.": "Autorisatie headers worden automatisch geïnjecteerd vanuit uw verbinding.",
  "GET": "KRIJG",
  "POST": "POSTE",
  "PATCH": "BEKIJK",
  "PUT": "PUT",
  "DELETE": "VERWIJDEREN",
  "HEAD": "HOOFD"
}