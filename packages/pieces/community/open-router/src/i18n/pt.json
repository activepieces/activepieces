{
  "Use any AI model to generate code, text, or images via OpenRouter.ai.": "Use qualquer modelo de IA para gerar código, texto ou imagens via OpenRouter.ai.",
  "\nFollow these instructions to get your OpenAI API Key:\n\n1. Visit the following website: https://openrouter.ai/keys.\n2. Once on the website, click on create a key.\n3. Once you have created a key, copy it and use it for the Api key field on the site.\n": "\nFollow these instructions to get your OpenAI API Key:\n\n1. Visit the following website: https://openrouter.ai/keys.\n2. Once on the website, click on create a key.\n3. Once you have created a key, copy it and use it for the Api key field on the site.\n",
  "Ask LLM": "Perguntar LLM",
  "Custom API Call": "Chamada de API personalizada",
  "Ask any model supported by Open Router.": "Pergunte qualquer modelo suportado pelo Open Router.",
  "Make a custom API call to a specific endpoint": "Faça uma chamada de API personalizada para um ponto de extremidade específico",
  "Model": "Modelo",
  "Prompt": "Aviso",
  "Temperature": "Temperatura",
  "Maximum Tokens": "Máximo de Tokens",
  "Top P": "Superior P",
  "Method": "Método",
  "Headers": "Cabeçalhos",
  "Query Parameters": "Parâmetros da consulta",
  "Body": "Conteúdo",
  "Response is Binary ?": "A resposta é binária ?",
  "No Error on Failure": "Nenhum erro no Failure",
  "Timeout (in seconds)": "Tempo limite (em segundos)",
  "The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code.": "O modelo que irá gerar a conclusão. Alguns modelos são adequados para tarefas de linguagem natural, outros são especializados no código.",
  "The prompt to send to the model.": "O prompt para enviar para o modelo.",
  "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.": "Controla aleatoriedade: Diminuir resulta em menos complementos aleatórios. À medida que a temperatura se aproxima de zero, o modelo se tornará determinístico e repetitivo.",
  "The maximum number of tokens to generate. Requests can use up to 2,048 or 4,096 tokens shared between prompt and completion, don't set the value to maximum and leave some tokens for the input. The exact limit varies by model. (One token is roughly 4 characters for normal English text)": "O número máximo de tokens a gerar. Solicitações podem usar até 2.048 ou 4.096 tokens compartilhados entre prompt e conclusão, não defina o valor como máximo e deixe algumas fichas para a entrada. O limite exato varia por modelo. (Um token é aproximadamente 4 caracteres para o texto normal em inglês)",
  "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.": "Uma alternativa à amostragem com temperatura, chamada amostragem núcleo, onde o modelo considera os resultados dos tokens com massa de probabilidade superior (P). Portanto, 0,1 significa que apenas os tokens que incluem a massa de probabilidade superior de 10% são considerados.",
  "Authorization headers are injected automatically from your connection.": "Os cabeçalhos de autorização são inseridos automaticamente a partir da sua conexão.",
  "Enable for files like PDFs, images, etc..": "Habilitar para arquivos como PDFs, imagens, etc..",
  "GET": "OBTER",
  "POST": "POSTAR",
  "PATCH": "COMPRAR",
  "PUT": "COLOCAR",
  "DELETE": "EXCLUIR",
  "HEAD": "CABEÇA"
}