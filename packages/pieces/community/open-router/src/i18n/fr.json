{
  "Use any AI model to generate code, text, or images via OpenRouter.ai.": "Utilisez n'importe quel modèle IA pour générer du code, du texte ou des images via OpenRouter.ai.",
  "\nFollow these instructions to get your OpenAI API Key:\n\n1. Visit the following website: https://openrouter.ai/keys.\n2. Once on the website, click on create a key.\n3. Once you have created a key, copy it and use it for the Api key field on the site.\n": "\nFollow these instructions to get your OpenAI API Key:\n\n1. Visit the following website: https://openrouter.ai/keys.\n2. Once on the website, click on create a key.\n3. Once you have created a key, copy it and use it for the Api key field on the site.\n",
  "Ask LLM": "Demander à LLM",
  "Custom API Call": "Appel API personnalisé",
  "Ask any model supported by Open Router.": "Demandez à n'importe quel modèle pris en charge par Open Router.",
  "Make a custom API call to a specific endpoint": "Passez un appel API personnalisé à un point de terminaison spécifique",
  "Model": "Modélisation",
  "Prompt": "Prompt",
  "Temperature": "Température",
  "Maximum Tokens": "Maximum de jetons",
  "Top P": "Top P",
  "Method": "Méthode",
  "Headers": "En-têtes",
  "Query Parameters": "Paramètres de requête",
  "Body": "Corps",
  "Response is Binary ?": "La réponse est Binaire ?",
  "No Error on Failure": "Aucune erreur en cas d'échec",
  "Timeout (in seconds)": "Délai d'attente (en secondes)",
  "The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code.": "Le modèle qui va générer la complétion. Certains modèles sont adaptés aux tâches de langage naturel, d'autres se spécialisent dans le code.",
  "The prompt to send to the model.": "L'invite à envoyer au modèle.",
  "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.": "Contrôle aléatoirement : La baisse des résultats est moins aléatoire, alors que la température approche de zéro, le modèle devient déterministe et répétitif.",
  "The maximum number of tokens to generate. Requests can use up to 2,048 or 4,096 tokens shared between prompt and completion, don't set the value to maximum and leave some tokens for the input. The exact limit varies by model. (One token is roughly 4 characters for normal English text)": "Le nombre maximum de jetons à générer. Les requêtes peuvent utiliser jusqu'à 2 048 ou 4 096 jetons partagés entre l'invite et la complétion, ne pas définir la valeur au maximum et laisser des jetons pour l'entrée. La limite exacte varie selon le modèle. (un jeton est d'environ 4 caractères pour le texte anglais normal)",
  "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.": "Une alternative à l'échantillonnage à la température, appelée l'échantillonnage du noyau, où le modèle considère les résultats des jetons avec la masse de probabilité top_p. Ainsi, 0,1 signifie que seuls les jetons constituant la masse de probabilité la plus élevée de 10% sont pris en compte.",
  "Authorization headers are injected automatically from your connection.": "Les en-têtes d'autorisation sont injectés automatiquement à partir de votre connexion.",
  "Enable for files like PDFs, images, etc..": "Activer pour les fichiers comme les PDFs, les images, etc.",
  "GET": "OBTENIR",
  "POST": "POSTER",
  "PATCH": "PATCH",
  "PUT": "EFFACER",
  "DELETE": "SUPPRIMER",
  "HEAD": "TÊTE"
}