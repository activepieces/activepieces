{
  "Extract structured data from websites using AI with natural language prompts": "使用自然语言提示从网站提取结构化数据",
  "\nFollow these steps to obtain your Firecrawl API Key:\n\n1. Visit [Firecrawl](https://firecrawl.dev) and create an account.\n2. Log in and navigate to your dashboard.\n3. Locate and copy your API key from the API settings section.\n": "\nFollow these steps to obtain your Firecrawl API Key:\n\n1. Visit [Firecrawl](https://firecrawl.dev) and create an account.\n2. Log in and navigate to your dashboard.\n3. Locate and copy your API key from the API settings section.\n",
  "Scrape Website": "查询网站",
  "Extract Structured Data": "提取结构化数据",
  "Crawl": "克劳尔",
  "Crawl Results": "Crawl 结果",
  "Map Websites": "地图网站",
  "Custom API Call": "自定义 API 呼叫",
  "Scrape a website by performing a series of actions like clicking, typing, taking screenshots, and extracting data.": "通过点击、输入、截图和提取数据等一系列操作来扫描一个网站。",
  "Extract structured data from multiple URLs using AI.": "使用 AI从多个网址提取结构化数据。",
  "Crawl multiple pages from a website based on specified rules and patterns.": "基于指定规则和模式的网站的 Crawl 多个页面。",
  "Get the results of a crawl job.": "获取一个 crawl 作业的结果。",
  "Input a website and get all the urls on the website.": "输入网站并获取网站上的所有网址。",
  "Make a custom API call to a specific endpoint": "将一个自定义 API 调用到一个特定的终点",
  "Website URL": "网站 URL",
  "Timeout (ms)": "超时(ms)",
  "Perform Actions Before Scraping": "在拆解前执行操作",
  "Action Properties": "动作属性",
  "Output Format": "输出格式",
  "Extraction Prompt": "提取提示",
  "Schema Mode": "Schema模式",
  "Data Definition": "数据定义",
  "URLs": "链接地址",
  "Enable Web Search": "启用网页搜索",
  "Timeout (seconds)": "超时(秒)",
  "Data Schema Type": "数据方案类型",
  "URL": "网址",
  "Prompt": "Prompt",
  "Limit": "限制",
  "Only Main Content": "仅主内容",
  "Deliver Results to Webhook": "将结果投递到 Webhook",
  "Webhook Properties": "Webhook 属性",
  "Crawl ID": "Crawl ID",
  "Main Website URL": "主网站 URL",
  "Include subdomain": "包括子域",
  "Method": "方法",
  "Headers": "信头",
  "Query Parameters": "查询参数",
  "Body Type": "正文类型",
  "Body": "正文内容",
  "Response is Binary ?": "响应是二进制的？",
  "No Error on Failure": "失败时没有错误",
  "Timeout (in seconds)": "超时(秒)",
  "Follow redirects": "跟随重定向",
  "The webpage URL to scrape.": "要扫描的网页 URL。",
  "Maximum time to wait for the page to load (in milliseconds).": "等待页面加载的最大时间 (毫秒)。",
  "Enable to perform a sequence of actions on the page before scraping (like clicking buttons, filling forms, etc.). See [Firecrawl Actions Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions) for details on available actions and their parameters.": "启用在拆解前在页面上执行一系列动作(如点击按钮、填充表单等)。 关于可用动作及其参数的详细信息，请参阅[Firecrawl Actions Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions)。",
  "Properties for actions that will be performed on the page.": "将在页面上执行的操作的属性。",
  "Choose what format you want your output in.": "选择您想要输出的格式。",
  "Prompt for extracting data.": "提示解压数据。",
  "Data schema type.": "数据模式类型。",
  "Add one or more URLs to extract data from.": "添加一个或多个URL来提取数据。",
  "Describe what information you want to extract.": "描述您想要提取的信息。",
  "Enable web search to find additional context.": "启用 Web 搜索以查找其他上下文.",
  "Timeout in seconds after which the task will be cancelled": "任务被取消的超时时间（秒）",
  "For complex schema, you can use advanced mode.": "对于复杂的模式，您可以使用高级模式。",
  "The base URL to start crawling from.": "要开始卷起的基础URL。",
  "Maximum number of pages to crawl. Default limit is 10.": "最大页面数到 crawl。默认限制是 10。",
  "Only return the main content of the page, excluding headers, navs, footers, etc.": "只返回页面的主要内容，不包括页眉、海军、页脚等。",
  "Enable to send crawl results to a webhook URL.": "启用可将 crawl 结果发送到Webhook URL。",
  "Properties for webhook configuration.": "Webhook 配置的属性。",
  "The ID of the crawl job to check.": "要检查的 crawl 作业的 ID。",
  "The webpage URL to start scraping from.": "开始拆解的网页 URL。",
  "Include and crawl pages from subdomains of the target website (e.g., blog.example.com, shop.example.com) in addition to the main domain.": "除了主域外，包括目标网站子域的网页(例如：blog.example.com、shop.example.com)。",
  "Maximum number of links to return (max: 100,000)": "返回的最大链接数 (最大: 100,000)",
  "Authorization headers are injected automatically from your connection.": "授权头自动从您的连接中注入。",
  "Enable for files like PDFs, images, etc.": "启用 PDF、图像等文件。",
  "Simple": "简单的",
  "Advanced": "高级版",
  "GET": "获取",
  "POST": "帖子",
  "PATCH": "PATCH",
  "PUT": "弹出",
  "DELETE": "删除",
  "HEAD": "黑色",
  "None": "无",
  "JSON": "JSON",
  "Form Data": "表单数据",
  "Raw": "原始文件"
}