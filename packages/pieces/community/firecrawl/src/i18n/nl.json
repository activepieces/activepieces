{
  "Extract structured data from websites using AI with natural language prompts": "Haal gestructureerde gegevens uit websites met behulp van AI met natuurlijke taalprompts uit",
  "\nFollow these steps to obtain your Firecrawl API Key:\n\n1. Visit [Firecrawl](https://firecrawl.dev) and create an account.\n2. Log in and navigate to your dashboard.\n3. Locate and copy your API key from the API settings section.\n": "\nVolg deze stappen om uw Firecrawl API Key te verkrijgen:\n\n1. Bezoek [Firecrawl](https://firecrawl.dev) en maak een account aan.\n2. Log in en navigeer naar uw dashboard.\n3. Zoek en kopieer uw API-sleutel vanuit de API-instellingen sectie.\n",
  "Scrape Website": "Scrape Website",
  "Extract Structured Data": "Extract gestructureerde gegevens",
  "Crawl": "Crawl",
  "Crawl Results": "Crawl resultaten",
  "Map Websites": "Kaart websites",
  "Custom API Call": "Custom API Call",
  "Scrape a website by performing a series of actions like clicking, typing, taking screenshots, and extracting data.": "Scrapen een website door een reeks acties uit te voeren zoals klikken, typen, screenshots maken en gegevens uitpakken.",
  "Extract structured data from multiple URLs using AI.": "Haal gestructureerde gegevens uit meerdere URL's met behulp van AI.",
  "Crawl multiple pages from a website based on specified rules and patterns.": "Crawl meerdere pagina's van een website gebaseerd op specifieke regels en patronen.",
  "Get the results of a crawl job.": "Krijg het resultaat van een crawl job.",
  "Input a website and get all the urls on the website.": "Voer een website in en krijg alle URL's op de website.",
  "Make a custom API call to a specific endpoint": "Maak een aangepaste API call naar een specifiek eindpunt",
  "Website URL": "Website URL",
  "Timeout (ms)": "Time-out (ms)",
  "Perform Actions Before Scraping": "Acties uitvoeren voor scraping",
  "Action Properties": "Actie Eigenschappen",
  "Output Format": "Uitvoer formaat",
  "Extraction Prompt": "Extractie Prompt",
  "Schema Mode": "Schema Modus",
  "Data Definition": "Datadefinitie",
  "URLs": "URL's",
  "Enable Web Search": "Web zoeken inschakelen",
  "Timeout (seconds)": "Time-out (seconden)",
  "Data Schema Type": "Data Schema Type",
  "URL": "URL",
  "Prompt": "Prompt",
  "Limit": "Limiet",
  "Only Main Content": "Alleen hoofdinhoud",
  "Deliver Results to Webhook": "Resultaten leveren aan Webhook",
  "Webhook Properties": "Webhook eigenschappen",
  "Crawl ID": "Crawl ID",
  "Main Website URL": "Hoofd Website URL",
  "Include subdomain": "Inclusief subdomein",
  "Method": "Methode",
  "Headers": "Kopteksten",
  "Query Parameters": "Query parameters",
  "Body": "Lichaam",
  "Response is Binary ?": "Antwoord is binair?",
  "No Error on Failure": "Geen fout bij fout",
  "Timeout (in seconds)": "Time-out (in seconden)",
  "The webpage URL to scrape.": "De URL van de webpagina om te scrapen.",
  "Maximum time to wait for the page to load (in milliseconds).": "Maximale wachttijd voor het laden van de pagina (in milliseconden).",
  "Enable to perform a sequence of actions on the page before scraping (like clicking buttons, filling forms, etc.). See [Firecrawl Actions Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions) for details on available actions and their parameters.": "Inschakelen om een reeks van acties uit te voeren op de pagina voordat u scrapt (zoals op knoppen, invullen van formulieren, enz.). Zie [Firecrawl Acties Documentatie](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions) voor meer informatie over beschikbare acties en hun parameters.",
  "Properties for actions that will be performed on the page.": "Eigenschappen voor acties die worden uitgevoerd op de pagina.",
  "Choose what format you want your output in.": "Kies in welk formaat je uitvoer wilt hebben.",
  "Prompt for extracting data.": "Naar uitpakken van gegevens.",
  "Data schema type.": "Data schema type.",
  "Add one or more URLs to extract data from.": "Voeg een of meer URL's toe om gegevens van te extraheren.",
  "Describe what information you want to extract.": "Beschrijf welke informatie je wilt extraheren.",
  "Enable web search to find additional context.": "Schakel webzoeken in om extra context te vinden.",
  "Timeout in seconds after which the task will be cancelled": "Time-out in seconden waarna de taak wordt geannuleerd",
  "For complex schema, you can use advanced mode.": "Voor complexe schema's kunt u de geavanceerde modus gebruiken.",
  "The base URL to start crawling from.": "De basis-URL waar gecrawt vanaf moet worden.",
  "Maximum number of pages to crawl. Default limit is 10.": "Maximum aantal pagina's om te crawen. Standaard limiet is 10.",
  "Only return the main content of the page, excluding headers, navs, footers, etc.": "Geef alleen de hoofdinhoud van de pagina, exclusief kopteksten, navs, voeten, enz.",
  "Enable to send crawl results to a webhook URL.": "Inschakelen om crawl resultaten te verzenden naar een webhook URL.",
  "Properties for webhook configuration.": "Eigenschappen voor webhook configuratie.",
  "The ID of the crawl job to check.": "Het ID van de crawl job om te controleren.",
  "The webpage URL to start scraping from.": "De webpagina-URL om te beginnen met scrapen.",
  "Include and crawl pages from subdomains of the target website (e.g., blog.example.com, shop.example.com) in addition to the main domain.": "Inclusief en crawl pagina's van subdomeinen van de doelwebsite (bijv. blog.example.com, shop.example.com) als aanvulling op het hoofddomein.",
  "Maximum number of links to return (max: 100,000)": "Maximum aantal terug te sturen links (max: 100,000)",
  "Authorization headers are injected automatically from your connection.": "Autorisatie headers worden automatisch ge√Ønjecteerd vanuit uw verbinding.",
  "Enable for files like PDFs, images, etc..": "Inschakelen voor bestanden zoals PDF's, afbeeldingen etc..",
  "Simple": "Eenvoudig",
  "Advanced": "Geavanceerd",
  "GET": "KRIJG",
  "POST": "POSTE",
  "PATCH": "BEKIJK",
  "PUT": "PUT",
  "DELETE": "VERWIJDEREN",
  "HEAD": "HOOFD"
}