{
  "Perplexity AI": "Perplexity AI",
  "AI powered search engine": "AI 驅動搜尋引擎",
  "\n  Navigate to [API Settings](https://www.perplexity.ai/settings/api) and create new API key.\n  ": "\n  導航至 [API 設置](https://www.perplexity.ai/settings/api) 然後創建新 API 鍵。\n  ",
  "Ask AI": "詢問 AI",
  "Enables users to generate prompt completion based on a specified model.": "讓用戶根據指定的模型生成提示完成。",
  "Model": " 模型",
  "Question": "問題",
  "Temperature": "溫度",
  "Maximum Tokens": "最大 Token",
  "Top P": "Top P",
  "Presence penalty": "Presence 懲罰",
  "Frequency penalty": "頻率懲罰",
  "Roles": "角色",
  "The amount of randomness in the response.Higher values are more random, and lower values are more deterministic.": "回應中的隨機程度。值越高，回應越隨機；值越低，回應越決斷。",
  "Please refer [guide](https://docs.perplexity.ai/guides/model-cards) for each model token limit.": "請參閱 [指南](https://docs.perplexity.ai/guides/model-cards) 確認每個模型的 token 限制。",
  "The nucleus sampling threshold, valued between 0 and 1 inclusive. For each subsequent token, the model considers the results of the tokens with top_p probability mass.": "核取樣閾值，值在 0 到 1 之間，對於每個後續 token，模型考慮具有 top_p 概率質量的 token 結果。",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the mode's likelihood to talk about new topics.": "從 -2.0 到 2.0 的數字。正值會懲罰新的 token，根據它們是否已經出現在文本中，增加模式討論新主題的可能性。",
  "A multiplicative penalty greater than 0. Values greater than 1.0 penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.": "乘數懲罰大於 0。值大於 1.0 的話，會根據 token 在文本中的現有頻率懲罰其出現次數，降低模型重複同一句話的可能性。",
  "Array of roles to specify more accurate response.After the (optional) system message, user and assistant roles should alternate with user then assistant, ending in user.": "角色的數組可指定更準確的回應。在（可選的）系統消息之後，使用者及助理角色交替開始，最終由使用者結束。",
  "sonar-reasoning-pro": "sonar-reasoning-pro",
  "sonar-reasoning": "sonar-reasoning",
  "sonar-pro": "sonar-pro",
  "sonar": "sonar"
}