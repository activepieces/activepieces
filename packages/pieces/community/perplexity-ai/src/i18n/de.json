{
  "Perplexity AI": "Perplexity AI",
  "AI powered search engine": "KI betriebene Suchmaschine",
  "\n  Navigate to [API Settings](https://www.perplexity.ai/settings/api) and create new API key.\n  ": "\n  Navigiere zu [API-Einstellungen](https://www.perplexity.ai/settings/api) und erstelle neuen API-Schlüssel.\n  ",
  "Ask AI": "KI fragen",
  "Enables users to generate prompt completion based on a specified model.": "Ermöglicht Benutzern die Fertigstellung der Eingabeaufforderung basierend auf einem bestimmten Modell.",
  "Model": "Modell",
  "Question": "Frage",
  "Temperature": "Temperatur",
  "Maximum Tokens": "Maximale Token",
  "Top P": "Oben P",
  "Presence penalty": "Präsenzstrafe",
  "Frequency penalty": "Frequenz Strafe",
  "Roles": "Rollen",
  "The amount of randomness in the response.Higher values are more random, and lower values are more deterministic.": "Die Anzahl der zufälligen Werte in der Response.Höhere Werte sind zufällig und niedrigere Werte sind deterministischer.",
  "Please refer [guide](https://docs.perplexity.ai/guides/model-cards) for each model token limit.": "Bitte beachten Sie [guide](https://docs.perplexity.ai/guides/model-cards) für jedes Modell-Token-Limit.",
  "The nucleus sampling threshold, valued between 0 and 1 inclusive. For each subsequent token, the model considers the results of the tokens with top_p probability mass.": "Der Schwellenwert für Nucleus Probenahme, der zwischen 0 und 1 inklusive ist. Bei jedem späteren Token berücksichtigt das Modell die Ergebnisse der Tokens mit der Top_p Wahrscheinlichkeitsmasse.",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the mode's likelihood to talk about new topics.": "Nummer zwischen -2.0 und 2.0. Positive Werte bestrafen neue Tokens je nachdem, ob sie bisher im Text erscheinen, was die Wahrscheinlichkeit erhöht, über neue Themen zu sprechen.",
  "A multiplicative penalty greater than 0. Values greater than 1.0 penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.": "Eine multiplikative Strafe, die größer als 0 ist. Werte größer als 1. bestrafen neue Token basierend auf ihrer bisherigen Häufigkeit im Text, wodurch die Wahrscheinlichkeit des Modells verringert wird, die gleiche Zeile wörtlich zu wiederholen.",
  "Array of roles to specify more accurate response.After the (optional) system message, user and assistant roles should alternate with user then assistant, ending in user.": "Array der Rollen, um eine genauere Antwort zu spezifizieren. Nach der (optionalen) Systemnachricht sollten Benutzer- und Assistentenrollen wechseln mit dem Benutzer und dann Assistenten, die im Benutzer enden.",
  "sonar-reasoning-pro": "sonar-reasoning-pro",
  "sonar-reasoning": "sonar-Argumentation",
  "sonar-pro": "sonar-pro",
  "sonar": "sonar"
}