{
  "Perplexity AI": "Perplexity AI",
  "AI powered search engine": "AI駆動検索エンジン",
  "\n  Navigate to [API Settings](https://www.perplexity.ai/settings/api) and create new API key.\n  ": "\n  [API Settings](https://www.perplexity.ai/settings/api) に移動し、新しい API キーを作成します。\n  ",
  "Ask AI": "AIに聞く",
  "Enables users to generate prompt completion based on a specified model.": "ユーザーが指定したモデルに基づいてプロンプト補完を生成できるようにします。",
  "Model": "モデル",
  "Question": "質問",
  "Temperature": "温度",
  "Maximum Tokens": "最大トークン",
  "Top P": "トップ P",
  "Presence penalty": "プレゼンスペナルティ",
  "Frequency penalty": "頻度ペナルティ",
  "Roles": "ロール",
  "The amount of randomness in the response.Higher values are more random, and lower values are more deterministic.": "応答におけるランダム性の量。値が大きいほど、値が小さい方が決定的になります。",
  "Please refer [guide](https://docs.perplexity.ai/guides/model-cards) for each model token limit.": "各モデルトークンの制限については、 [guide](https://docs.perplexity.ai/guides/model-cards) を参照してください。",
  "The nucleus sampling threshold, valued between 0 and 1 inclusive. For each subsequent token, the model considers the results of the tokens with top_p probability mass.": "0~1の範囲の核サンプリングしきい値。 後続の各トークンについて、モデルはtop_p確率質量を持つトークンの結果を考慮します。",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the mode's likelihood to talk about new topics.": "-2.0 から 2.0 までの数字。 肯定的な値は、これまでのところテキストに表示されるかどうかに基づいて新しいトークンを罰し、モードが新しいトピックについて話す可能性を高めます。",
  "A multiplicative penalty greater than 0. Values greater than 1.0 penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.": "0 より大きい乗算ペナルティ。1より大きい値。 これまでのテキスト内の既存の頻度に基づいて新しいトークンを罰すると、モデルが同じ行を元に繰り返す可能性が低下します。",
  "Array of roles to specify more accurate response.After the (optional) system message, user and assistant roles should alternate with user then assistant, ending in user.": "より正確な応答を指定するためのロールの配列(任意)システムメッセージの後、ユーザーとアシスタントのロールは、ユーザーで終了し、その後、アシスタントを代替する必要があります。",
  "sonar-reasoning-pro": "sonar-reasoning-pro",
  "sonar-reasoning": "ソナーの推論は",
  "sonar-pro": "sonar-pro",
  "sonar": "sonar"
}