{
  "Groq": "格罗克",
  "Use Groq's fast language models and audio processing capabilities.": "使用Groq的快速语言模型和音频处理能力。",
  "Enter your Groq API Key": "输入您的 Groq API 密钥",
  "Ask AI": "询问AI",
  "Transcribe Audio": "翻译音频",
  "Translate Audio": "翻译音频",
  "Custom API Call": "自定义 API 呼叫",
  "Ask Groq anything using fast language models.": "使用快速语言模型询问Groq。",
  "Transcribes audio into text in the input language.": "以输入语言将音频转换为文本。",
  "Translates audio into English text.": "将音频翻译成英文文本。",
  "Make a custom API call to a specific endpoint": "将一个自定义 API 调用到一个特定的终点",
  "Model": "模型",
  "Question": "问",
  "Temperature": "温度",
  "Maximum Tokens": "最大令牌",
  "Top P": "顶部 P",
  "Frequency penalty": "频率处罚",
  "Presence penalty": "存在的处罚",
  "Memory Key": "内存键",
  "Roles": "角色",
  "Audio File": "音频文件",
  "Language": "语言",
  "Prompt": "Prompt",
  "Response Format": "响应格式",
  "Method": "方法",
  "Headers": "信头",
  "Query Parameters": "查询参数",
  "Body": "正文内容",
  "No Error on Failure": "失败时没有错误",
  "Timeout (in seconds)": "超时(秒)",
  "The model which will generate the completion.": "生成完成的模型。",
  "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.": "随机性控制：降低结果的随机性能。当温度接近零时，模型将变成确定性和重复性。",
  "The maximum number of tokens to generate. The total length of input tokens and generated tokens is limited by the model's context length.": "要生成的最大令牌数。输入令牌和生成令牌的总长度受模型上下文长度的限制。",
  "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.": "一种替代用温度取样的办法，称为核取样，即模型考虑了带有顶部_p 概率质量的代币结果。 所以0.1表示仅考虑了最高概率10%的代币。",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.": "在 2.0 和 2.0 之间的数字。 正数值根据到目前为止文本中现有的频率对新令牌进行惩罚，从而减少了模式重复同一行逐字的可能性。",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.": "在 2.0 和 2.0 之间的数字。 积极的价值观因为迄今为止是否出现在案文中而使新的代币受到惩罚，从而增加了模式讨论新专题的可能性。",
  "A memory key that will keep the chat history shared across runs and flows. Keep it empty to leave Groq without memory of previous messages.": "一个内存密钥将保持聊天历史在运行和流量之间共享。留空则离开Groq而不保存以前的消息。",
  "Array of roles to specify more accurate response": "角色数组以指定更准确的响应",
  "The audio file to transcribe. Supported formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.": "要转换的音频文件。支持格式：flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm。",
  "The model to use for transcription.": "用于翻译的模型。",
  "The language of the input audio in ISO-639-1 format (e.g., \"en\" for English). This will improve accuracy and latency.": "ISO-639-1格式输入音频的语言(例如英文的“en”)，这将提高准确性和延迟性。",
  "An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.": "一个可选的文本来引导模型的风格或继续上一个音频段。提示应该匹配音频语言。",
  "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.": "取样温度，介于 0 和 1 之间。 将使输出更具有随机性，而像0.2这样较低的值将使其更加集中和决定性的。",
  "The format of the transcript output.": "字幕输出的格式。",
  "The audio file to translate. Supported formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.": "要翻译的音频文件。支持格式：flac、mp3、mp4、mpeg、mpga、m4a、ogg、wav、webm。",
  "The model to use for translation.": "用于翻译的模型。",
  "An optional text in English to guide the model's style or continue a previous audio segment.": "一个可选的英文文本来引导模型的风格或继续上一个音频部分。",
  "The format of the translation output.": "翻译输出的格式。",
  "Authorization headers are injected automatically from your connection.": "授权头自动从您的连接中注入。",
  "JSON": "JSON",
  "Text": "文本",
  "Verbose JSON": "Verbose JSON",
  "GET": "获取",
  "POST": "帖子",
  "PATCH": "PATCH",
  "PUT": "弹出",
  "DELETE": "删除",
  "HEAD": "黑色"
}