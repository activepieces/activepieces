{
  "LocalAI": "本地AI",
  "The free, Self-hosted, community-driven and local-first. Drop-in replacement for OpenAI running on consumer-grade hardware. No GPU required.": "免费的、自托管的、社区驱动的和本地的第一个。Drop-inplace for OpenAI运行在消费级硬件上。无需GPU。",
  "Server URL": "服务器 URL",
  "Access Token": "访问令牌",
  "LocalAI Instance URL": "LocalAI Instance URL",
  "LocalAI Access Token": "本地AI 访问令牌",
  "Ask LocalAI": "查询 localAI",
  "Custom API Call": "自定义 API 呼叫",
  "Ask LocalAI anything you want!": "询问您想要的 LocalAI",
  "Make a custom API call to a specific endpoint": "将一个自定义 API 调用到一个特定的终点",
  "Model": "模型",
  "Question": "问",
  "Temperature": "温度",
  "Maximum Tokens": "最大令牌",
  "Top P": "顶部 P",
  "Frequency penalty": "频率处罚",
  "Presence penalty": "存在的处罚",
  "Roles": "角色",
  "Method": "方法",
  "Headers": "信头",
  "Query Parameters": "查询参数",
  "Body": "正文内容",
  "Response is Binary ?": "响应是二进制的？",
  "No Error on Failure": "失败时没有错误",
  "Timeout (in seconds)": "超时(秒)",
  "The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code.": "生成完成的模型。一些模型适合于自然语言任务，其他模型则专门用于代码。",
  "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.": "随机性控制：降低结果的随机性能。当温度接近零时，模型将变成确定性和重复性。",
  "The maximum number of tokens to generate. Requests can use up to 2,048 or 4,096 tokens shared between prompt and completion, don't set the value to maximum and leave some tokens for the input. The exact limit varies by model. (One token is roughly 4 characters for normal English text)": "要生成的令牌的最大数量。 请求最多可使用2,048个或4,096个即时和完成之间共享的令牌， 不将值设置为最大值并留下一些令牌用于输入。 确切限制因型号而异。(普通英文文本一个令牌大约为4个字符)",
  "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.": "一种替代用温度取样的办法，称为核取样，即模型考虑了带有顶部_p 概率质量的代币结果。 所以0.1表示仅考虑了最高概率10%的代币。",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.": "在 2.0 和 2.0 之间的数字。 正数值根据到目前为止文本中现有的频率对新令牌进行惩罚，从而减少了模式重复同一行逐字的可能性。",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the mode's likelihood to talk about new topics.": "在 2.0 和 2.0 之间的数字。 积极的价值因为新的代币是否出现在案文中而使其受到惩罚，从而增加了模式谈论新专题的可能性。",
  "Array of roles to specify more accurate response": "角色数组以指定更准确的响应",
  "Authorization headers are injected automatically from your connection.": "授权头自动从您的连接中注入。",
  "Enable for files like PDFs, images, etc..": "启用 PDF、图像等文件。",
  "GET": "获取",
  "POST": "帖子",
  "PATCH": "PATCH",
  "PUT": "弹出",
  "DELETE": "删除",
  "HEAD": "黑色"
}