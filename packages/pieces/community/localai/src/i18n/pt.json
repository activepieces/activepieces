{
  "LocalAI": "AI local",
  "The free, Self-hosted, community-driven and local-first. Drop-in replacement for OpenAI running on consumer-grade hardware. No GPU required.": "O livre, Auto-hospedado, impulsionado pela comunidade e local-primeiro. Substituição de drop-in para OpenAI rodando em hardware de nível de consumidor. Não é necessária GPU.",
  "Server URL": "URL do servidor",
  "Access Token": "Token de acesso",
  "LocalAI Instance URL": "LocalAI Instance URL",
  "LocalAI Access Token": "Token de acesso LocalAI",
  "Ask LocalAI": "Perguntar LocalAI",
  "Custom API Call": "Chamada de API personalizada",
  "Ask LocalAI anything you want!": "Pergunte ao LocalAI o que você quiser!",
  "Make a custom API call to a specific endpoint": "Faça uma chamada de API personalizada para um ponto de extremidade específico",
  "Model": "Modelo",
  "Question": "Questão",
  "Temperature": "Temperatura",
  "Maximum Tokens": "Máximo de Tokens",
  "Top P": "Superior P",
  "Frequency penalty": "Penalidade de frequência",
  "Presence penalty": "Penalidade de presença",
  "Roles": "Papéis",
  "Method": "Método",
  "Headers": "Cabeçalhos",
  "Query Parameters": "Parâmetros da consulta",
  "Body": "Conteúdo",
  "Response is Binary ?": "A resposta é binária ?",
  "No Error on Failure": "Nenhum erro no Failure",
  "Timeout (in seconds)": "Tempo limite (em segundos)",
  "The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code.": "O modelo que irá gerar a conclusão. Alguns modelos são adequados para tarefas de linguagem natural, outros são especializados no código.",
  "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.": "Controla aleatoriedade: Diminuir resulta em menos complementos aleatórios. À medida que a temperatura se aproxima de zero, o modelo se tornará determinístico e repetitivo.",
  "The maximum number of tokens to generate. Requests can use up to 2,048 or 4,096 tokens shared between prompt and completion, don't set the value to maximum and leave some tokens for the input. The exact limit varies by model. (One token is roughly 4 characters for normal English text)": "O número máximo de tokens a gerar. Solicitações podem usar até 2.048 ou 4.096 tokens compartilhados entre prompt e conclusão, não defina o valor como máximo e deixe algumas fichas para a entrada. O limite exato varia por modelo. (Um token é aproximadamente 4 caracteres para o texto normal em inglês)",
  "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.": "Uma alternativa à amostragem com temperatura, chamada amostragem núcleo, onde o modelo considera os resultados dos tokens com massa de probabilidade superior (P). Portanto, 0,1 significa que apenas os tokens que incluem a massa de probabilidade superior de 10% são considerados.",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.": "Número entre -2.0 e 2.0. Valores positivos penalizam novos tokens baseados em sua frequência existente no texto até agora, diminuindo a probabilidade do modelo repetir o verbal da mesma linha.",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the mode's likelihood to talk about new topics.": "Número entre -2.0 e 2.0. Valores positivos penalizam novos tokens baseado no fato de eles aparecerem no texto até agora, aumentando a probabilidade de o modo falar sobre novos tópicos.",
  "Array of roles to specify more accurate response": "Array de papéis para especificar uma resposta mais precisa",
  "Authorization headers are injected automatically from your connection.": "Os cabeçalhos de autorização são inseridos automaticamente a partir da sua conexão.",
  "Enable for files like PDFs, images, etc..": "Habilitar para arquivos como PDFs, imagens, etc..",
  "GET": "OBTER",
  "POST": "POSTAR",
  "PATCH": "COMPRAR",
  "PUT": "COLOCAR",
  "DELETE": "EXCLUIR",
  "HEAD": "CABEÇA"
}